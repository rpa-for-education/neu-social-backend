// app.js
import "dotenv/config";
import express from "express";
import cors from "cors";
import { callLLM } from "./llm.js";
import { socialVectorSearch, initEmbedding } from "./search.js";

const app = express();
const PORT = process.env.PORT || 4000;
const DEFAULT_MODEL_ID = process.env.DEFAULT_MODEL_ID || "qwen-max";

// ===== Middleware =====
app.use(cors()); // âœ… Cho phÃ©p má»i origin gá»i API
app.use(express.json({ limit: "10mb" }));

// Debug log middleware
app.use((req, res, next) => {
  console.log("ðŸ“© Request:", {
    method: req.method,
    url: req.url,
    body: req.body,
  });
  next();
});

// ===== Chuáº©n hÃ³a context =====
function buildPrompt(question, socials = []) {
  let context =
    "Báº¡n lÃ  trá»£ lÃ½ há»c thuáº­t, tráº£ lá»i ngáº¯n gá»n, cÃ³ trÃ­ch dáº«n bÃ i viáº¿t liÃªn quan.\n\n";

  if (socials.length) {
    context += "Danh sÃ¡ch bÃ i viáº¿t:\n";
    socials.slice(0, 10).forEach((s, i) => {
      context += `BÃ i viáº¿t ${i + 1}:
- NgÆ°á»i Ä‘Äƒng: ${s.id_nguoi_dung || "KhÃ´ng rÃµ"} 
- Thá»i gian: ${
        s.created_time && s.created_time !== "0000-00-00 00:00:00"
          ? s.created_time
          : s.inserted_time || "KhÃ´ng rÃµ"
      }
- Ná»™i dung: ${s.noi_dung_bai_viet?.slice(0, 200) || "KhÃ´ng cÃ³"}...
- LÆ°á»£t thÃ­ch: ${s.like || 0}, BÃ¬nh luáº­n: ${s.comment || 0}, Chia sáº»: ${s.share || 0}
- Link: ${s.url || "KhÃ´ng cÃ³"}\n\n`;
    });
  } else {
    context += "KhÃ´ng tÃ¬m tháº¥y bÃ i viáº¿t phÃ¹ há»£p.\n\n";
  }

  context += `\nCÃ¢u há»i: ${question}\n\nHÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t hoáº·c ngÃ´n ngá»¯ cá»§a cÃ¢u há»i.`;
  return context;
}

// ===== Agent API =====
app.post("/api/agent", async (req, res) => {
  try {
    const { question, model_id = DEFAULT_MODEL_ID, topk = 5 } = req.body || {};
    if (!question?.trim()) {
      return res.status(400).json({ error: "Missing question" });
    }

    let socials = [];
    try {
      socials = await socialVectorSearch(question, Number(topk));
      console.log(`ðŸ”Ž Found ${socials.length} socials from DB`);
    } catch (e) {
      console.error("âŒ Social vector search failed:", e);
    }

    const prompt = buildPrompt(question, socials);

    let answerText = "";
    try {
      const resp = await callLLM(prompt, model_id);

      // ðŸ”‘ Ã‰p káº¿t quáº£ thÃ nh string an toÃ n
      answerText =
        typeof resp === "string"
          ? resp
          : resp?.text || resp?.output || JSON.stringify(resp, null, 2);
    } catch (e) {
      console.error("âŒ LLM call failed:", e);
      return res
        .status(500)
        .json({ error: "LLM call failed", details: e.message });
    }

    res.json({
      model_id,
      answer: answerText || "âŒ KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i.",
      retrieved: { social: socials },
    });
  } catch (e) {
    console.error("âŒ API /api/agent error:", e);
    res.status(500).json({ error: e.message });
  }
});

// ===== Boot =====
if (!process.env.VERCEL) {
  app.listen(PORT, async () => {
    console.log(`âž¡ï¸ API listening on http://localhost:${PORT}`);
    initEmbedding().catch((e) =>
      console.error("Embedding preload failed:", e.message)
    );
  });
}

export default app;
